{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:02:59.478299Z",
     "start_time": "2018-11-21T15:02:59.270856Z"
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# spacy, textblob and nltk for language processing\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# sklearn for feature extraction & modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB         # Naive Bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:04:43.865221Z",
     "start_time": "2018-11-21T15:04:43.862984Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('float_format', '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BBC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:05:14.370542Z",
     "start_time": "2018-11-21T15:05:14.295219Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('..', 'data', 'bbc')\n",
    "files = path.glob('**/*.txt')\n",
    "doc_list = []\n",
    "for i, file in enumerate(files):\n",
    "    topic = file.parts[-2]\n",
    "    article = file.read_text(encoding='latin1').split('\\n')\n",
    "    heading = article[0].strip()\n",
    "    body = ' '.join([l.strip() for l in article[1:]]).strip()\n",
    "    doc_list.append([topic, heading, body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:05:34.973260Z",
     "start_time": "2018-11-21T15:05:34.966964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 3 columns):\n",
      "topic      2225 non-null object\n",
      "heading    2225 non-null object\n",
      "body       2225 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 52.2+ KB\n"
     ]
    }
   ],
   "source": [
    "docs = pd.DataFrame(doc_list, columns=['topic', 'heading', 'body'])\n",
    "docs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:08.577908Z",
     "start_time": "2018-11-21T15:03:08.572433Z"
    }
   },
   "source": [
    "## Introduction to TextBlob\n",
    "\n",
    "You should already have downloaded TextBlob, a Python library used to explore common NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select random article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:08:20.231706Z",
     "start_time": "2018-11-21T15:08:20.228950Z"
    }
   },
   "outputs": [],
   "source": [
    "article = docs.sample(1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:08:20.445883Z",
     "start_time": "2018-11-21T15:08:20.438173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic:\tEntertainment\n",
      "\n",
      "Lee to create new film superhero\n",
      "\n",
      "Comic book veteran Stan Lee is to team up with producer Robert Evans to create a movie featuring a new superhero.  Foreverman will focus on a character who has to face problems in everyday life as well as using his special powers to save the world. Paramount Pictures, the studio behind the film, have revealed few details about the project but say it has the potential to spawn a series of films. Lee is best known for his work on Spider-Man and The Incredible Hulk.  He is collaborating on the script with screenwriter Peter Briggs, who penned the recent comic book adaptation Hellboy. \"We believe it to be truly a whole new franchise,\" said Gill Champion, president and chief executive of Lee's POW! Entertainment. \"In this world where people are looking for something different, Stan's idea was to create a concept not seen before to become an evergreen franchise for Paramount.\" Many of Lee's other creations, including X-Men and Daredevil, have been turned into films in the past five years. However, the Spider-Man series has been the biggest box office hit, with the 2002 original and its 2004 sequel taking almost $1.6bn (Â£857m) worldwide. A third Spider-Man film is scheduled for release in 2007. Another Marvel Comics adaptation, The Fantastic Four, will be released in cinemas this summer.\n"
     ]
    }
   ],
   "source": [
    "print(f'Topic:\\t{article.topic.capitalize()}\\n\\n{article.heading}\\n')\n",
    "print(article.body.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:08:33.752095Z",
     "start_time": "2018-11-21T15:08:33.743030Z"
    }
   },
   "outputs": [],
   "source": [
    "parsed_body = TextBlob(article.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:09:22.969222Z",
     "start_time": "2018-11-21T15:09:22.944416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Comic', 'book', 'veteran', 'Stan', 'Lee', 'is', 'to', 'team', 'up', 'with', 'producer', 'Robert', 'Evans', 'to', 'create', 'a', 'movie', 'featuring', 'a', 'new', 'superhero', 'Foreverman', 'will', 'focus', 'on', 'a', 'character', 'who', 'has', 'to', 'face', 'problems', 'in', 'everyday', 'life', 'as', 'well', 'as', 'using', 'his', 'special', 'powers', 'to', 'save', 'the', 'world', 'Paramount', 'Pictures', 'the', 'studio', 'behind', 'the', 'film', 'have', 'revealed', 'few', 'details', 'about', 'the', 'project', 'but', 'say', 'it', 'has', 'the', 'potential', 'to', 'spawn', 'a', 'series', 'of', 'films', 'Lee', 'is', 'best', 'known', 'for', 'his', 'work', 'on', 'Spider-Man', 'and', 'The', 'Incredible', 'Hulk', 'He', 'is', 'collaborating', 'on', 'the', 'script', 'with', 'screenwriter', 'Peter', 'Briggs', 'who', 'penned', 'the', 'recent', 'comic', 'book', 'adaptation', 'Hellboy', 'We', 'believe', 'it', 'to', 'be', 'truly', 'a', 'whole', 'new', 'franchise', 'said', 'Gill', 'Champion', 'president', 'and', 'chief', 'executive', 'of', 'Lee', \"'s\", 'POW', 'Entertainment', 'In', 'this', 'world', 'where', 'people', 'are', 'looking', 'for', 'something', 'different', 'Stan', \"'s\", 'idea', 'was', 'to', 'create', 'a', 'concept', 'not', 'seen', 'before', 'to', 'become', 'an', 'evergreen', 'franchise', 'for', 'Paramount', 'Many', 'of', 'Lee', \"'s\", 'other', 'creations', 'including', 'X-Men', 'and', 'Daredevil', 'have', 'been', 'turned', 'into', 'films', 'in', 'the', 'past', 'five', 'years', 'However', 'the', 'Spider-Man', 'series', 'has', 'been', 'the', 'biggest', 'box', 'office', 'hit', 'with', 'the', '2002', 'original', 'and', 'its', '2004', 'sequel', 'taking', 'almost', '1.6bn', 'Â£857m', 'worldwide', 'A', 'third', 'Spider-Man', 'film', 'is', 'scheduled', 'for', 'release', 'in', '2007', 'Another', 'Marvel', 'Comics', 'adaptation', 'The', 'Fantastic', 'Four', 'will', 'be', 'released', 'in', 'cinemas', 'this', 'summer'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_body.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence boundary detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:09:33.354426Z",
     "start_time": "2018-11-21T15:09:33.350233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Comic book veteran Stan Lee is to team up with producer Robert Evans to create a movie featuring a new superhero.\"),\n",
       " Sentence(\"Foreverman will focus on a character who has to face problems in everyday life as well as using his special powers to save the world.\"),\n",
       " Sentence(\"Paramount Pictures, the studio behind the film, have revealed few details about the project but say it has the potential to spawn a series of films.\"),\n",
       " Sentence(\"Lee is best known for his work on Spider-Man and The Incredible Hulk.\"),\n",
       " Sentence(\"He is collaborating on the script with screenwriter Peter Briggs, who penned the recent comic book adaptation Hellboy.\"),\n",
       " Sentence(\"\"We believe it to be truly a whole new franchise,\" said Gill Champion, president and chief executive of Lee's POW!\"),\n",
       " Sentence(\"Entertainment.\"),\n",
       " Sentence(\"\"In this world where people are looking for something different, Stan's idea was to create a concept not seen before to become an evergreen franchise for Paramount.\"\"),\n",
       " Sentence(\"Many of Lee's other creations, including X-Men and Daredevil, have been turned into films in the past five years.\"),\n",
       " Sentence(\"However, the Spider-Man series has been the biggest box office hit, with the 2002 original and its 2004 sequel taking almost $1.6bn (Â£857m) worldwide.\"),\n",
       " Sentence(\"A third Spider-Man film is scheduled for release in 2007.\"),\n",
       " Sentence(\"Another Marvel Comics adaptation, The Fantastic Four, will be released in cinemas this summer.\")]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_body.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:16:35.655521Z",
     "start_time": "2018-11-21T15:16:35.644382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('producer', 'produc'),\n",
       " ('Evans', 'evan'),\n",
       " ('create', 'creat'),\n",
       " ('movie', 'movi'),\n",
       " ('featuring', 'featur'),\n",
       " ('character', 'charact'),\n",
       " ('problems', 'problem'),\n",
       " ('using', 'use'),\n",
       " ('powers', 'power'),\n",
       " ('Pictures', 'pictur'),\n",
       " ('revealed', 'reveal'),\n",
       " ('details', 'detail'),\n",
       " ('potential', 'potenti'),\n",
       " ('series', 'seri'),\n",
       " ('films', 'film'),\n",
       " ('Incredible', 'incred'),\n",
       " ('collaborating', 'collabor'),\n",
       " ('screenwriter', 'screenwrit'),\n",
       " ('Briggs', 'brigg'),\n",
       " ('penned', 'pen'),\n",
       " ('adaptation', 'adapt'),\n",
       " ('believe', 'believ'),\n",
       " ('truly', 'truli'),\n",
       " ('franchise', 'franchis'),\n",
       " ('president', 'presid'),\n",
       " ('executive', 'execut'),\n",
       " ('Entertainment', 'entertain'),\n",
       " ('people', 'peopl'),\n",
       " ('looking', 'look'),\n",
       " ('something', 'someth'),\n",
       " ('different', 'differ'),\n",
       " ('create', 'creat'),\n",
       " ('before', 'befor'),\n",
       " ('become', 'becom'),\n",
       " ('franchise', 'franchis'),\n",
       " ('Many', 'mani'),\n",
       " ('creations', 'creation'),\n",
       " ('including', 'includ'),\n",
       " ('turned', 'turn'),\n",
       " ('films', 'film'),\n",
       " ('years', 'year'),\n",
       " ('However', 'howev'),\n",
       " ('series', 'seri'),\n",
       " ('office', 'offic'),\n",
       " ('original', 'origin'),\n",
       " ('its', 'it'),\n",
       " ('taking', 'take'),\n",
       " ('worldwide', 'worldwid'),\n",
       " ('scheduled', 'schedul'),\n",
       " ('release', 'releas'),\n",
       " ('Another', 'anoth'),\n",
       " ('Comics', 'comic'),\n",
       " ('adaptation', 'adapt'),\n",
       " ('Fantastic', 'fantast'),\n",
       " ('released', 'releas'),\n",
       " ('cinemas', 'cinema')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize stemmer.\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Stem each word.\n",
    "[(word, stemmer.stem(word)) for i, word in enumerate(parsed_body.words) \n",
    " if word.lower() != stemmer.stem(parsed_body.words[i])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:14:59.476144Z",
     "start_time": "2018-11-21T15:14:59.471406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('has', 'ha'),\n",
       " ('problems', 'problem'),\n",
       " ('as', 'a'),\n",
       " ('as', 'a'),\n",
       " ('powers', 'power'),\n",
       " ('details', 'detail'),\n",
       " ('has', 'ha'),\n",
       " ('films', 'film'),\n",
       " ('was', 'wa'),\n",
       " ('creations', 'creation'),\n",
       " ('films', 'film'),\n",
       " ('years', 'year'),\n",
       " ('has', 'ha'),\n",
       " ('its', 'it'),\n",
       " ('cinemas', 'cinema')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(word, word.lemmatize()) for i, word in enumerate(parsed_body.words) \n",
    " if word != parsed_body.words[i].lemmatize()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization relies on parts-of-speech (POS) tagging; `spaCy` performs POS tagging, here we make assumptions, e.g. that each token is verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:15:25.550554Z",
     "start_time": "2018-11-21T15:15:25.545309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 'be'),\n",
       " ('featuring', 'feature'),\n",
       " ('has', 'have'),\n",
       " ('using', 'use'),\n",
       " ('powers', 'power'),\n",
       " ('revealed', 'reveal'),\n",
       " ('details', 'detail'),\n",
       " ('has', 'have'),\n",
       " ('films', 'film'),\n",
       " ('is', 'be'),\n",
       " ('known', 'know'),\n",
       " ('is', 'be'),\n",
       " ('collaborating', 'collaborate'),\n",
       " ('penned', 'pen'),\n",
       " ('said', 'say'),\n",
       " ('are', 'be'),\n",
       " ('looking', 'look'),\n",
       " ('was', 'be'),\n",
       " ('seen', 'see'),\n",
       " ('including', 'include'),\n",
       " ('been', 'be'),\n",
       " ('turned', 'turn'),\n",
       " ('films', 'film'),\n",
       " ('has', 'have'),\n",
       " ('been', 'be'),\n",
       " ('taking', 'take'),\n",
       " ('is', 'be'),\n",
       " ('scheduled', 'schedule'),\n",
       " ('released', 'release')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(word, word.lemmatize(pos='v')) for i, word in enumerate(parsed_body.words) \n",
    " if word != parsed_body.words[i].lemmatize(pos='v')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Textblob Lemmatization with `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:18:17.058469Z",
     "start_time": "2018-11-21T15:18:17.050714Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    words = TextBlob(text.lower()).words\n",
    "    return [word.lemmatize() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:18:17.216997Z",
     "start_time": "2018-11-21T15:18:17.210693Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=lemmatizer, decode_error='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
